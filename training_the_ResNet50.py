# -*- coding: utf-8 -*-
"""Training the model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rbf-OvI2DigK-Shnr-ekLR5BxmDLecxj
"""

from google.colab import drive

drive.mount('/content/gdrive')

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import pathlib
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.python.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from keras import backend as K
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array
import pandas as pd
import shutil
import re
from collections import Counter

f1 = len(os.listdir('/content/gdrive/MyDrive/RAF-corrected-genders/female'))
f2 = len(os.listdir('/content/gdrive/MyDrive/RAF-corrected-genders/male'))
print(f1 + f2)

tf.test.gpu_device_name()

dataset_path = "/content/gdrive/MyDrive/RAF-corrected-genders"

data_dir = pathlib.Path(dataset_path)

img_height,img_width=100,100
batch_size=16
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds_df = pd.DataFrame()
train_ds_df = pd.DataFrame()
val_ds_filenames = []
train_ds_filenames = []

for image_path in val_ds.file_paths:

    string = image_path
    filename = string.split('/')[-1]
    val_ds_filenames.append(filename)

for image_path in train_ds.file_paths:

    string = image_path
    filename = string.split('/')[-1]
    train_ds_filenames.append(filename)

val_ds_df['filename'] = val_ds_filenames
train_ds_df['filename'] = train_ds_filenames

val_ds_df.to_csv('/content/gdrive/MyDrive/validation-dataframe')
train_ds_df.to_csv('/content/gdrive/MyDrive/training-dataframe')

df = pd.read_csv('/content/gdrive/MyDrive/RAF-DB-table-format.csv')

df['full-file-name'] = '/content/gdrive/MyDrive/RAF-corrected-races/' + df['race'] + '/' + df['file-name']

df['full-file-name'][15]

my_count = dict()

for i in range(len(df.index)):
  my_count[df['full-file-name'][i]] = df['gender'][i]

# ['female', 'male']
gender_cnt_train_ds = []
gender_cnt_val_ds = []

for image_path in train_ds.file_paths:

    string = image_path

    new_string = re.sub(r'_aligned.*\.jpg', '_aligned.jpg', string)

    if my_count[new_string] != 'male' and my_count[new_string] != 'female':
      continue

    gender_cnt_train_ds.append(my_count[new_string])

for image_path in val_ds.file_paths:

    string = image_path

    new_string = re.sub(r'_aligned.*\.jpg', '_aligned.jpg', string)

    if my_count[new_string] != 'male' and my_count[new_string] != 'female':
      continue

    gender_cnt_val_ds.append(my_count[new_string])

fig, ax = plt.subplots(1, 2, figsize = (12, 5))

ax[0].hist(gender_cnt_train_ds, bins = 10, color = ['lightblue'])
ax[0].set_title('Gender distribution of the train dataset')
ax[0].set_xlabel('Gender type')
ax[0].set_ylabel('Number of images')

ax[1].hist(gender_cnt_val_ds, bins = 10, color = ['lightgreen'])
ax[1].set_title('Gender distribution of the validation dataset')
ax[1].set_xlabel('Gender type')
ax[1].set_ylabel('Number of images')

plt.show()

class_names = train_ds.class_names
print(class_names)

resnet_model = Sequential()

pretrained_model= tf.keras.applications.ResNet101(include_top=False,
                   input_shape=(100,100,3),
                   pooling='avg',
                   weights='imagenet')
# for layer in pretrained_model.layers:
        # layer.trainable=False

# print(len(pretrained_model.layers))

for layer in pretrained_model.layers[:-7]:
    layer.trainable = False

resnet_model.add(pretrained_model)
resnet_model.add(Flatten())
resnet_model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))
resnet_model.add(Dropout(0.5))
resnet_model.add(BatchNormalization())
resnet_model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))
resnet_model.add(Dropout(0.5))
resnet_model.add(BatchNormalization())
# resnet_model.add(Dense(128, activation='relu'))
# resnet_model.add(Dropout(0.7))
# resnet_model.add(BatchNormalization())
# resnet_model.add(Dense(64, activation='relu'))
# resnet_model.add(Dropout(0.7))
# resnet_model.add(BatchNormalization())
resnet_model.add(Dense(2, activation='sigmoid'))

resnet_model.summary()

resnet_model.compile(optimizer=Adam(lr=0.001111510225611776),loss='sparse_categorical_crossentropy',metrics=['accuracy'])

epochs=20
history = resnet_model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

resnet_model.save('/content/gdrive/MyDrive/trained-resnet50/')



fig1 = plt.gcf()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.axis(ymin=0.4,ymax=1)
plt.grid()
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'validation'])
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.grid()
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'validation'])
plt.show()

female_data_dir = os.path.join(data_dir, 'female')
male_data_dir = os.path.join(data_dir, 'male')

female_predictions = []
male_predictions = []

for filename in os.listdir(female_data_dir):
    img_path = os.path.join(female_data_dir, filename)
    img = image.load_img(img_path, target_size=(100, 100))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    preds = resnet_model.predict(x)

    predicted_class = np.argmax(preds)

    if(predicted_class == 0):
      female_predictions.append(1)
    else:
      female_predictions.append(0)

for filename in os.listdir(male_data_dir):
    img_path = os.path.join(male_data_dir, filename)
    img = image.load_img(img_path, target_size=(100, 100))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    preds = resnet_model.predict(x)

    predicted_class = np.argmax(preds)

    if(predicted_class == 1):
      male_predictions.append(1)
    else:
      male_predictions.append(0)

fig, ax = plt.subplots(1, 2)

incorrect_count = female_predictions.count(0)
correct_count = female_predictions.count(1)

total_count = len(female_predictions)
incorrect_percentage = (incorrect_count / total_count) * 100
correct_percentage = (correct_count / total_count) * 100

sizes = [incorrect_percentage, correct_percentage]
colors = ['lightblue', 'lightgreen']
explode = (0.1, 0)

ax[0].pie(sizes, explode=explode, colors=colors, autopct='%1.1f%%', startangle=90)
ax[0].axis('equal')
ax[0].legend(labels)
ax[0].set_title('Female prediction results')



incorrect_count = male_predictions.count(0)
correct_count = male_predictions.count(1)

total_count = len(male_predictions)
incorrect_percentage = (incorrect_count / total_count) * 100
correct_percentage = (correct_count / total_count) * 100

sizes = [incorrect_percentage, correct_percentage]
colors = ['lightblue', 'lightgreen']
explode = (0.1, 0)

ax[1].pie(sizes, explode=explode, colors=colors, autopct='%1.1f%%', startangle=90)
ax[1].axis('equal')
ax[1].legend(labels)
ax[1].set_title('Male prediction results')

plt.show()



"""Model to run in race"""

dataset_path = "/content/gdrive/MyDrive/RAF-corrected-races"

data_dir = pathlib.Path(dataset_path)

img_height,img_width=100,100
batch_size=16
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

my_count = dict()

for i in range(len(df.index)):
  my_count[df['full-file-name'][i]] = df['race'][i]

gender_cnt_train_ds = []
gender_cnt_val_ds = []

for image_path in train_ds.file_paths:

    string = image_path

    new_string = re.sub(r'_aligned.*\.jpg', '_aligned.jpg', string)

    # if my_count[new_string] != 'male' and my_count[new_string] != 'female':
      # continue

    gender_cnt_train_ds.append(my_count[new_string])

for image_path in val_ds.file_paths:

    string = image_path

    new_string = re.sub(r'_aligned.*\.jpg', '_aligned.jpg', string)

    # if my_count[new_string] != 'male' and my_count[new_string] != 'female':
      # continue

    gender_cnt_val_ds.append(my_count[new_string])

fig, ax = plt.subplots(1, 2, figsize = (12, 5))

ax[0].hist(gender_cnt_train_ds, bins = 10, color = ['lightblue'])
ax[0].set_title('Race distribution of the train dataset')
ax[0].set_xlabel('Race type')
ax[0].set_ylabel('Number of images')

ax[1].hist(gender_cnt_val_ds, bins = 10, color = ['lightgreen'])
ax[1].set_title('Race distribution of the validation dataset')
ax[1].set_xlabel('Race type')
ax[1].set_ylabel('Number of images')

plt.show()

class_names = train_ds.class_names
print(class_names)

resnet_model = Sequential()

pretrained_model= tf.keras.applications.ResNet50(include_top=False,
                   input_shape=(100,100,3),
                   pooling='avg',
                   weights='imagenet')
# for layer in pretrained_model.layers:
        # layer.trainable=False

# print(len(pretrained_model.layers))

for layer in pretrained_model.layers[:-7]:
    layer.trainable = False

resnet_model.add(pretrained_model)
resnet_model.add(Flatten())
resnet_model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))
resnet_model.add(Dropout(0.5))
resnet_model.add(BatchNormalization())
resnet_model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))
resnet_model.add(Dropout(0.5))
resnet_model.add(BatchNormalization())
# resnet_model.add(Dense(128, activation='relu'))
# resnet_model.add(Dropout(0.7))
# resnet_model.add(BatchNormalization())
# resnet_model.add(Dense(64, activation='relu'))
# resnet_model.add(Dropout(0.7))
# resnet_model.add(BatchNormalization())
resnet_model.add(Dense(3, activation='softmax'))

resnet_model.summary()

resnet_model.compile(optimizer=Adam(lr=0.001111510225611776),loss='sparse_categorical_crossentropy',metrics=['accuracy'])

epochs=20
history = resnet_model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

fig1 = plt.gcf()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.axis(ymin=0.4,ymax=1)
plt.grid()
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'validation'])
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.grid()
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'validation'])
plt.show()

# ['African-American', 'Asian', 'Caucasian']

african_american_data_dir = os.path.join(data_dir, 'African-American')
asian_data_dir = os.path.join(data_dir, 'Asian')
caucasian_data_dir = os.path.join(data_dir, 'Caucasian')

african_american_predictions = []
asian_predictions = []
caucasian_predictions = []

race_dir = [african_american_data_dir, asian_data_dir, caucasian_data_dir]
race_predictions = [african_american_predictions, asian_predictions, caucasian_predictions]
race_names = ['African-American', 'Asian', 'Caucasian']



for i in range(3):
  for filename in os.listdir(race_dir[i]):
    img_path = os.path.join(race_dir[i], filename)
    img = image.load_img(img_path, target_size=(100, 100))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    preds = resnet_model.predict(x)

    predicted_class = np.argmax(preds)

    if(predicted_class == i):
      race_predictions[i].append(1)
    else:
      race_predictions[i].append(0)

fig, ax = plt.subplots(1, 3)

for i in range(3):
  incorrect_count = race_predictions[i].count(0)
  correct_count = race_predictions[i].count(1)
  total_count = len(race_predictions[i])
  incorrect_percentage = (incorrect_count / total_count) * 100
  correct_percentage = (correct_count / total_count) * 100

  sizes = [incorrect_percentage, correct_percentage]
  colors = ['lightblue', 'lightgreen', 'lightred']
  explode = (0.1, 0)

  ax[i].pie(sizes, explode=explode, colors=colors, autopct='%1.1f%%', startangle=90)
  ax[i].axis('equal')
  labels = ['Incorrect', 'Correct']
  ax[i].legend(labels)
  ax[i].set_title(f'{race_names[i]} results')

len(race_predictions[2]) + len(race_predictions[1]) + len(race_predictions[0])

plt.bar(['African-American size', 'Asian size', 'Caucasian size'], [len(race_predictions[0]), len(race_predictions[1]),
                                                                    len(race_predictions[2])], color = ['lightblue', 'lightgreen', 'orange'])
plt.title('Size of race datasets')
plt.xlabel('Race type')
plt.ylabel('Number of images')
plt.show()





len(race_predictions[2])







"""Model for age"""

dataset_path = "/content/gdrive/MyDrive/RAF-corrected-ages"

data_dir = pathlib.Path(dataset_path)

img_height,img_width=100,100
batch_size=16
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

my_count = dict()

for i in range(len(df.index)):
  my_count[df['full-file-name'][i]] = df['age'][i]

gender_cnt_train_ds = []
gender_cnt_val_ds = []

for image_path in train_ds.file_paths:

    string = image_path

    new_string = re.sub(r'_aligned.*\.jpg', '_aligned.jpg', string)

    # if my_count[new_string] != 'male' and my_count[new_string] != 'female':
      # continue

    gender_cnt_train_ds.append(my_count[new_string])

for image_path in val_ds.file_paths:

    string = image_path

    new_string = re.sub(r'_aligned.*\.jpg', '_aligned.jpg', string)

    # if my_count[new_string] != 'male' and my_count[new_string] != 'female':
      # continue

    gender_cnt_val_ds.append(my_count[new_string])

fig, ax = plt.subplots(1, 2, figsize = (12, 5))

ax[0].hist(gender_cnt_train_ds, bins = 10, color = ['lightblue'])
ax[0].set_title('Age distribution of the train dataset')
ax[0].set_xlabel('Age range')
ax[0].set_ylabel('Number of images')

ax[1].hist(gender_cnt_val_ds, bins = 10, color = ['lightgreen'])
ax[1].set_title('Age distribution of the validation dataset')
ax[1].set_xlabel('Age range')
ax[1].set_ylabel('Number of images')

plt.show()

class_names = train_ds.class_names
print(class_names)

resnet_model = Sequential()

pretrained_model= tf.keras.applications.ResNet50(include_top=False,
                   input_shape=(100,100,3),
                   pooling='avg',
                   weights='imagenet')
# for layer in pretrained_model.layers:
        # layer.trainable=False

# print(len(pretrained_model.layers))

for layer in pretrained_model.layers[:-7]:
    layer.trainable = False

resnet_model.add(pretrained_model)
resnet_model.add(Flatten())
resnet_model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))
resnet_model.add(Dropout(0.5))
resnet_model.add(BatchNormalization())
resnet_model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))
resnet_model.add(Dropout(0.5))
resnet_model.add(BatchNormalization())
# resnet_model.add(Dense(128, activation='relu'))
# resnet_model.add(Dropout(0.7))
# resnet_model.add(BatchNormalization())
# resnet_model.add(Dense(64, activation='relu'))
# resnet_model.add(Dropout(0.7))
# resnet_model.add(BatchNormalization())
resnet_model.add(Dense(5, activation='softmax'))

resnet_model.summary()

resnet_model.compile(optimizer=Adam(lr=0.001111510225611776),loss='sparse_categorical_crossentropy',metrics=['accuracy'])

epochs=20
history = resnet_model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

fig1 = plt.gcf()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.axis(ymin=0.4,ymax=1)
plt.grid()
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'validation'])
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.grid()
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'validation'])
plt.show()

# ['0-3', '20-39', '4-19', '40-69', '70+']

f1 = os.path.join(data_dir, '0-3')
f2 = os.path.join(data_dir, '20-39')
f3 = os.path.join(data_dir, '4-19')
f4 = os.path.join(data_dir, '40-69')
f5 = os.path.join(data_dir, '70+')

f1_predictions = []
f2_predictions = []
f3_predictions = []
f4_predictions = []
f5_predictions = []

age_dir = [f1, f2, f3, f4, f5]
age_predictions = [f1_predictions, f2_predictions, f3_predictions, f4_predictions, f5_predictions]
age_names = ['0-3', '20-39', '4-19', '40-69', '70+']

for i in range(5):
  for filename in os.listdir(age_dir[i]):
    img_path = os.path.join(age_dir[i], filename)
    img = image.load_img(img_path, target_size=(100, 100))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    preds = resnet_model.predict(x)

    predicted_class = np.argmax(preds)

    if(predicted_class == i):
      age_predictions[i].append(1)
    else:
      age_predictions[i].append(0)

fig, ax = plt.subplots(1, 5)

for i in range(5):
  incorrect_count = age_predictions[i].count(0)
  correct_count = age_predictions[i].count(1)
  total_count = len(age_predictions[i])
  incorrect_percentage = (incorrect_count / total_count) * 100
  correct_percentage = (correct_count / total_count) * 100

  sizes = [incorrect_percentage, correct_percentage]
  colors = ['lightblue', 'lightgreen', 'lightred']
  explode = (0.1, 0)

  ax[i].pie(sizes, explode=explode, colors=colors, autopct='%1.1f%%', startangle=90)
  ax[i].axis('equal')
  labels = ['Incorrect', 'Correct']
  ax[i].legend(labels)
  ax[i].set_title(f'{age_names[i]} results')

plt.bar(['0-3', '20-39', '4-19', '40-69', '70+'],
        [len(age_predictions[0]), len(age_predictions[1]), len(age_predictions[2]),
         len(age_predictions[3]), len(age_predictions[4])], color = ['lightblue', 'lightgreen', 'orange', 'peachpuff', 'linen'])
plt.title('Size of age datasets')
plt.xlabel('Age range')
plt.ylabel('Number of images')
plt.show()









